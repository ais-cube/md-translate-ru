Данные длинного контекста.
Наш набор данных для обучения на длинных контекстах включает как естественные, так и синтетические данные. Естественные данные отобраны из книг, научных статей и документов из корпусов общего предобучения с применением многоэтапной фильтрации (PPL, дедупликация, длина) и увеличения выборки из доменов с высокой концентрацией знаний. При создании синтетических данных, вдохновившись NextLong[11] и EntropyLong[18], мы использовали разнообразные методы для построения дальних зависимостей. Высокосхожие тексты агрегировались посредством чередующейся упаковки для формирования последовательностей с целью смягчения эффекта «потери в середине» и улучшения производительности в широком спектре задач с длинным контекстом. На этапе 200K мы дополнительно включили небольшую долю данных типа MRCR с несколькими вариантами, разработанными для расширения исходной парадигмы OpenAI, чтобы усилить возможность воспроизведения в расширенных многоходовых диалогах. Эмпирически мы обнаружили, что увеличение разнообразия данных постепенно повышает производительность модели на длинных контекстах; примечательно, что последующий этап промежуточного обучения на 200K, основанный на начальной фазе 128K, дополнительно укрепил производительность модели даже в пределах контекстного окна 128K.
2.4
Инфраструктура обучения
2.4.1
Эффективность памяти
Гибкое размещение MTP. При чередующемся конвейерном параллелизме [31] компоненты модели гибко назначаются этапам. Модуль MTP охватывает компоненты эмбеддинга, трансформера и вывода. Он требует существенно большего использования памяти, чем другие модули, что приводит к дисбалансу на уровне этапов. Мы размещаем выходной слой MTP вместе с основным выходным слоем на финальном этапе для обеспечения совместного использования параметров, одновременно помещая его компоненты эмбеддинга и трансформера на предшествующий этап. Это снижает нагрузку на память финального этапа и улучшает баланс между рангами конвейера.
Шардирование градиентов Pipeline ZeRO2. Каждый ранг конвейера поддерживает несколько этапов [31], и в наивной реализации каждому этапу требуется полный буфер градиентов для накопления и обновлений оптимизатора. Вдохновившись ZeRO2 [38], мы шардируем градиенты между рангами параллелизма по данным, так что каждый этап хранит только долю 1/dp от полных градиентов. Кроме того, мы сохраняем полные буферы накопления только для двух этапов одновременно и повторно используем их через двойную буферизацию. Пока один буфер этапа накапливает градиенты по последовательным микропакетам, синхронизация градиентов для предыдущего буфера этапа выполняется параллельно. Это сокращает постоянную память градиентов до шардированных буферов для каждого этапа плюс только два полных буфера для скользящего накопления, без дополнительных накладных расходов на синхронизацию на практике.
Коммуникация без избыточности для распределенного оптимизатора Muon. Наивные реализации Muon выполняют all-gather полных параметров модели на каждом ранге параллелизма по данным, вызывая временные скачки памяти и избыточную коммуникацию. Мы ограничиваем all-gather шардами параметров, принадлежащими каждому рангу, и перекрываем локальные вычисления с коммуникацией шардов. Это устраняет избыточную коммуникацию и значительно снижает пиковые накладные расходы памяти, связанные с оптимизатором.
Выгрузка активаций конвейера. Во время прогрева конвейера прямое выполнение опережает обратное распространение, продлевая время жизни промежуточных активаций. Мы выгружаем активации в память хоста после прямого выполнения и перезагружаем их перед обратным выполнением [58]. Выгрузка применяется на уровне гранулярности слоев для дальнейшего снижения пикового использования памяти. В сочетании с детализированным перевычислением это в значительной степени устраняет необходимость хранения активаций в памяти GPU. Выгрузка и перезагрузка планируются так, чтобы перекрываться с вычислениями, избегая конфликтов с коммуникацией peer-to-peer и маршрутизацией токенов MoE (диспетчеризация и комбинирование). Это существенно сокращает объём памяти для активаций практически без накладных расходов.
Разделение последовательности на фрагменты при выходной проекции для снижения пиковой памяти. Выходная проекция и кросс-энтропийная функция потерь создают временные накладные расходы памяти от хранения активаций для обратного распространения и их повышения до более высокой точности во время вычисления потерь. Для снижения этих накладных расходов мы разбиваем входную последовательность на меньшие фрагменты и независимо вычисляем проекцию и потери для каждого фрагмента, завершая прямой и обратный проходы и освобождая активации перед переходом к следующему. В результате пиковое использование памяти снижается с увеличением числа фрагментов. При соответствующем количестве фрагментов этот подход снижает нагрузку на память выходного слоя, сохраняя производительность, сопоставимую с выполнением без разделения на фрагменты.
2.4.2
Эффективность параллелизма
Эффективное отложенное вычисление градиентов весов. Для сокращения простоев конвейера мы откладываем некоторые вычисления градиентов весов критического пути [37]. Детализированная отсрочка с оптимизированным хранением и перекрытием коммуникации улучшает пропускную способность, сохраняя накладные расходы памяти в ограниченных пределах.
9