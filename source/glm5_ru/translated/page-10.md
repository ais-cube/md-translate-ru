Tools
User message 1
Input
Reasoning 1
Tool call 1
Output
Tools
User message 1
Input
Reasoning 2
Tool call 2
Output
Reasoning 1
Tool call 1
Tool result 1
Tools
User message 1
Input
Reasoning 3
Answer 
Output
Reasoning 1
Tool call 1
Tool result 1
Reasoning 2
Tool call 2
Tool result 2
Tools
User message 1
Input
Reasoning 4
...
Output
Tool call 1
Tool result 1
Tool call 2
Tool result 2
Step 1
Step 2
Step 3
Step 1
 Чередующееся рассуждение между вызовами инструментов
Turn 2
User message 2
Answer 
Turn 1
Tools
User message 1
Input
Reasoning 4
...
Output
Reasoning 1
Tool call 1
Tool result 1
Reasoning 2
Tool call 2
Tool result 2
Step 1
Turn 2
User message 2
Reasoning 3
Answer 
без сохранённого рассуждения
с сохранённым рассуждением
или
Рисунок 7: Иллюстрация чередующегося рассуждения и сохранённого рассуждения.
Эффективное обучение на длинных последовательностях. Более длинные последовательности усугубляют дисбаланс нагрузки между группами параллелизма по данным и конвейерного параллелизма. Мы решаем эту проблему путём переупорядочивания последовательностей с учётом рабочей нагрузки, динамического перераспределения вычислений внимания и гибкого разделения рангов параллелизма по данным на группы контекстного параллелизма различных размеров [12; 47]. Иерархический all-to-all перекрывает внутриузловую и межузловую коммуникацию для QKV-тензоров для снижения задержки.
2.4.3
Обучение с учётом квантования INT4
Для обеспечения лучшей точности при низкой точности вычислений мы применяем QAT INT4 на этапе SFT. Более того, для дальнейшего снижения накладных расходов на время обучения мы разработали ядро квантования, применимое как к обучению, так и к автономному квантованию весов, что гарантирует побитово идентичное поведение между обучением и инференсом.
3
Пост-обучение
Фаза пост-обучения GLM-5 направлена на преобразование базовой модели в высокоэффективного ассистента с надёжными способностями рассуждения, программирования и агентными способностями. Как показано на рисунке 5, наш конвейер следует стратегии прогрессивного выравнивания: начиная с многозадачного контролируемого файн-тюнинга (SFT), который вводит продвинутые режимы чередующегося рассуждения, за которым следуют специализированные этапы обучения с подкреплением (RL) для задач рассуждения и агентных задач, и завершая общим этапом RL для выравнивания по человеческому стилю. Используя межэтапную дистилляцию on-policy в качестве финального уточнения, GLM-5 эффективно смягчает регрессию способностей, одновременно используя прирост производительности от каждого этапа обучения.
3.1
Контролируемый файн-тюнинг
По сравнению с GLM-4.5, GLM-5 значительно расширяет масштаб данных Agent и Coding на этапе SFT. Корпус SFT GLM-5 охватывает три основные категории:
• Общий диалог: ответы на вопросы, написание, ролевые игры, перевод, многошаговый диалог и взаимодействия с длинным контекстом;
• Рассуждение: математическое, программное и научное рассуждение;
• Программирование и агенты: код фронтенд- и бэкенд-разработки, вызов инструментов, агенты программирования, агенты поиска и агенты общего назначения.
10