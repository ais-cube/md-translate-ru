Стратегия обучения. Эти сигналы совместно оптимизируются в процессе RL для повышения структурной корректности генерируемого HTML, улучшения организации макета и повышения общего качества визуальной эстетики. Помимо разработки функций вознаграждения, мы изменяем обучающее распределение посредством динамической выборки. В частности, доля структурно тривиальных образцов вероятностно отбрасывается, что позволяет оптимизации сосредоточиться на более сложных страницах и повысить устойчивость в сценариях сложной композиции. Мы также применяем функцию потерь градиента политики на уровне токенов для стабилизации оптимизации [57]. Кроме того, мы вводим стратегию балансировки, которая распределяет различные результаты rollout одного и того же образца по нескольким обучающим пакетам, снижая смещение оптимизации и повышая стабильность обучения.

Rejection sampling. На этапе rejection sampling функции вознаграждения, используемые в RL, переносятся в конвейер фильтрации данных для построения высококачественного обучающего подмножества. На уровне страницы критерии фильтрации включают корректность кода и возможность компиляции. На уровне траектории мы дополнительно применяем ограничения корректности выполнения инструментов и глобального разнообразия содержимого, обеспечивая структурную согласованность. Мы применяем стратегию выбора Best-of-N, при которой из нескольких независимо сгенерированных кандидатов сохраняется образец наивысшего качества. Этот механизм эффективно перевешивает распределение в сторону экземпляров более высокого качества, что приводит к повышению эффективности выборки и усилению стабильности обучения.

Коррекция на основе маскирования. Хотя rejection sampling удаляет большую часть низкокачественных выходных данных, некоторые траектории содержат дефекты, ограниченные лишь небольшим числом страниц. Отбрасывание таких образцов снизило бы эффективное использование данных и увеличило бы затраты на генерацию. Для решения этой проблемы мы вводим механизм коррекции на основе маскирования, который автоматически идентифицирует дефектные страницы и применяет маскирование, сохраняя при этом высококачественное содержимое в той же траектории. Эта выборочная коррекция сохраняет ценные сигналы обучения с учителем, повышает эффективную эффективность данных и снижает избыточные затраты на регенерацию, тем самым повышая общую эффективность обучения.

Эмпирические улучшения. Доля сгенерированных страниц, строго соответствующих соотношению сторон 16:9, увеличивается с 40% до 92%, что сопровождается существенным сокращением случаев переполнения страниц. Оценка экспертами дополнительно показывает, что по сравнению с GLM-4.5 модель GLM-5 достигает показателей победы 60% в качестве содержимого, 57,5% в рациональности макета и 65% в визуальной эстетике, что приводит к общему показателю победы 67,5%. Эти результаты предоставляют эмпирическое подтверждение эффективности предложенной многоуровневой схемы вознаграждения и структуры самосовершенствования.

5 Адаптация GLM-5 к китайской чиповой инфраструктуре

Адаптация GLM-5 к разнообразным китайским чиповым инфраструктурам представляет значительные трудности из-за гетерогенности аппаратных экосистем, что часто осложняет высокопроизводительное развертывание. Несмотря на эти препятствия, мы успешно реализовали полностековую адаптацию для GLM-5 благодаря тесному сотрудничеству с семью основными китайскими чиповыми платформами, включая Huawei Ascend, Moore Threads, Hygon, Cambricon, Kunlunxin, MetaX и Enflame. В этом разделе мы используем серию Ascend Atlas в качестве примера для демонстрации нашей методологии адаптации, фокусируясь на трех основных столпах: экстремальная квантизация, высокопроизводительное слияние ядер и продвинутое планирование механизма вывода.

Квантизация смешанной точности W4A8. Чтобы разместить модель GLM-5 с 750 млрд параметров на одной машине Atlas 800T A3, мы реализовали сложную стратегию квантизации смешанной точности W4A8. Используя инструмент msModelSlim 7, мы применили специфическую точность к различным компонентам модели: стандартные блоки Attention и MLP используют W8A8 (INT8), в то время как эксперты MoE сжимаются до W4A8 (INT4) для радикального снижения объема памяти без значительной потери точности. Для поддержания стабильности при развертывании с низкой разрядностью были применены продвинутые алгоритмы, такие как QuaRot [2] для подавления выбросов и Flex_AWQ_SSZ для калибровки масштабирования.

Высокопроизводительные слитые ядра. Для преодоления вычислительных узких мест разреженного внимания на NPU Ascend мы разработали набор настроенных слитых ядер: Lightning Indexer, Sparse Flash Attention и MLAPO (Multi-head Latent Attention Pre-processing Optimization). Lightning Indexer интегрирует вычисление оценки, ReLU и операции TopK в одно ядро, что позволяет

7https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/80RC3alpha003/d
evaids/auxiliarydevtool/modelslim_0001.html

21