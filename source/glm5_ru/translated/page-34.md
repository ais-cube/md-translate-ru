[40] Z. Shao, P. Wang, Q. Zhu, R. Xu, J. Song, X. Bi, H. Zhang, M. Zhang, Y. Li, Y. Wu, et al.
Deepseekmath: Pushing the limits of mathematical reasoning in open language models. arXiv
preprint arXiv:2402.03300, 2024.
[41] V. Sirdeshmukh, K. Deshpande, J. Mols, L. Jin, E.-Y. Cardona, D. Lee, J. Kritz, W. Primack,
S. Yue, and C. Xing. Multichallenge: A realistic multi-turn conversation evaluation benchmark
challenging to frontier llms, 2025.
[42] H. F. Team. Harbor: A framework for evaluating and optimizing agents and models in container
environments., 2026.
[43] K. Team, T. Bai, Y. Bai, Y. Bao, S. Cai, Y. Cao, Y. Charles, H. Che, C. Chen, G. Chen, et al.
Kimi k2. 5: Visual agentic intelligence. arXiv preprint arXiv:2602.02276, 2026.
[44] L. Team, A. Shen, B. Li, B. Hu, B. Jing, C. Chen, C. Huang, C. Zhang, C. Yang, C. Lin, et al.
Every step evolves: Scaling reinforcement learning for trillion-scale thinking model. arXiv
preprint arXiv:2510.18855, 2025.
[45] T. T.-B. Team. Terminal-bench: A benchmark for ai agents in terminal environments, Apr 2025.
[46] Y. Tian, C. Wang, Z. Liu, H. Huang, W. Yu, D. Song, J. Tang, and Y. Guo. Beyond literal
mapping: Benchmarking and improving non-literal translation evaluation, 2026.
[47] Y. Wang, S. Wang, S. Zhu, F. Fu, X. Liu, X. Xiao, H. Li, J. Li, F. Wu, and B. Cui. Flexsp:
Accelerating large language model training via flexible sequence parallelism. In ASPLOS'25,
pages 421–436, 2025.
[48] Z. Wang, T. Shi, J. He, M. Cai, J. Zhang, and D. Song. Cybergym: Evaluating ai agents' cyber-
security capabilities with real-world vulnerabilities at scale. arXiv preprint arXiv:2506.02548,
2025.
[49] J. Wei, N. Karina, H. W. Chung, Y. J. Jiao, S. Papay, A. Glaese, J. Schulman, and W. Fedus.
Measuring short-form factuality in large language models, 2024.
[50] J. Wei, Z. Sun, S. Papay, S. McKinney, J. Han, I. Fulford, H. W. Chung, A. T. Passos, W. Fedus,
and A. Glaese. Browsecomp: A simple yet challenging benchmark for browsing agents. arXiv
preprint arXiv:2504.12516, 2025.
[51] L.-C. Xiaomi. Mimo-v2-flash technical report, 2026.
[52] A. Yang, A. Li, B. Yang, B. Zhang, and et al.
Qwen3 technical report.
arXiv preprint
arXiv:2505.09388, 2025.
[53] J. Yang, K. Lieret, C. E. Jimenez, A. Wettig, K. Khandpur, Y. Zhang, B. Hui, O. Press,
L. Schmidt, and D. Yang. Swe-smith: Scaling data for software engineering agents. arXiv
preprint arXiv:2504.21798, 2025.
[54] S. Yang, J. Kautz, and A. Hatamizadeh. Gated delta networks: Improving mamba2 with delta
rule. In ICLR'24, 2024.
[55] S. Yao, N. Shinn, P. Razavi, and K. Narasimhan. tau-bench: A benchmark for tool-agent-user
interaction in real-world domains. arXiv preprint arXiv:2406.12045, 2024.
[56] H. Yen, T. Gao, M. Hou, K. Ding, D. Fleischer, P. Izsak, M. Wasserblat, and D. Chen. Helmet:
How to evaluate long-context language models effectively and thoroughly. arXiv preprint
arXiv:2410.02694, 2024.
[57] Q. Yu, Z. Zhang, R. Zhu, Y. Yuan, X. Zuo, Y. Yue, W. Dai, T. Fan, G. Liu, L. Liu, et al. Dapo:
An open-source llm reinforcement learning system at scale. arXiv preprint arXiv:2503.14476,
2025.
[58] T. Yuan, Y. Liu, X. Ye, S. Zhang, J. Tan, B. Chen, C. Song, and D. Zhang. Accelerating the
training of large language models using efficient activation rematerialization and optimal hybrid
parallelism. In USENIX ATC'24, pages 545–561, 2024.
34