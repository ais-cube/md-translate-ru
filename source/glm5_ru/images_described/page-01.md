# page-01.png

> **Контекст:** GLM-5: from Vibe Coding to Agentic Engineering
GLM-5 Team
Zhipu AI & Tsinghua University
(For the complete list of authors, please refer to the Contribution section)
Abstract
We present GLM-5, a next-

---

## Тип изображения
Диаграмма / графическое сравнение результатов

## Краткое описание
Изображение демонстрирует результаты сравнительного тестирования модели GLM-5 с конкурирующими моделями (DeepSeek-V3.2, Claude Opus 4.5, Gemini 3 Pro, GPT-5.2) на восьми различных бенчмарках, охватывающих задачи агентной работы, логического мышления и программирования. GLM-5 показывает лидирующие или конкурентоспособные результаты на большинстве тестов.

## Структура изображения
Диаграмма состоит из восьми столбчатых графиков, расположенных в два ряда по четыре графика в каждом. Каждый график представляет отдельный бенчмарк с пятью вертикальными столбцами (по одному для каждой модели). GLM-5 выделена синим цветом с логотипом "Z", остальные модели показаны серыми столбцами с различными логотипами. Под каждым графиком указано название бенчмарка. Числовые значения отображены над столбцами.

## Текстовые элементы

| Оригинал (EN) | Перевод (RU) | Расположение |
|---|---|---|
| GLM-5: from Vibe Coding to Agentic Engineering | GLM-5: от интуитивного кодирования к агентной инженерии | заголовок документа |
| GLM-5 Team | Команда GLM-5 | подзаголовок |
| Zhipu AI & Tsinghua University | Zhipu AI и Университет Цинхуа | информация об авторах |
| (For the complete list of authors, please refer to the Contribution section) | (Полный список авторов см. в разделе "Вклад") | примечание |
| Abstract | Аннотация | заголовок раздела |
| We present GLM-5, a next-generation foundation model designed to transition the paradigm of vibe coding to agentic engineering. | Мы представляем GLM-5 — фундаментальную модель нового поколения, разработанную для перехода от парадигмы интуитивного кодирования к агентной инженерии. | текст аннотации |
| Building upon the agentic, reasoning, and coding (ARC) capabilities of its predecessor, GLM-5 adopts DSA to significantly reduce training and inference costs while maintaining long-context fidelity. | Опираясь на агентные возможности, логическое мышление и программирование (ARC) своего предшественника, GLM-5 использует DSA для значительного снижения затрат на обучение и вывод при сохранении точности работы с длинным контекстом. | текст аннотации |
| To advance model alignment and autonomy, we implement a new asynchronous reinforcement learning infrastructure that drastically improves post-training efficiency by decoupling generation from training. | Для улучшения выравнивания и автономности модели мы внедрили новую асинхронную инфраструктуру обучения с подкреплением, которая радикально повышает эффективность пост-обучения путем разделения генерации и обучения. | текст аннотации |
| Furthermore, we propose novel asynchronous agent RL algorithms that further improve RL quality by enabling the model to learn from complex, long-horizon interactions more effectively. | Кроме того, мы предлагаем новые асинхронные агентные RL-алгоритмы, которые дополнительно повышают качество RL, позволяя модели более эффективно учиться на сложных долгосрочных взаимодействиях. | текст аннотации |
| Through these innovations, GLM-5 achieves state-of-the-art performance on major open benchmarks. | Благодаря этим инновациям GLM-5 достигает передовых результатов на основных открытых бенчмарках. | текст аннотации |
| Most critically, GLM-5 demonstrates unprecedented capability in real-world coding tasks, surpassing previous baselines in handling end-to-end software engineering challenges. | Самое главное, GLM-5 демонстрирует беспрецедентные возможности в реальных задачах программирования, превосходя предыдущие базовые показатели в решении комплексных задач программной инженерии. | текст аннотации |
| Code, models, and more information are available at https://github.com/zai-org/GLM-5. | Код, модели и дополнительная информация доступны по адресу https://github.com/zai-org/GLM-5. | текст аннотации |
| GLM-5 | GLM-5 | легенда диаграммы |
| DeepSeek-V3.2 | DeepSeek-V3.2 | легенда диаграммы |
| Claude Opus 4.5 | Claude Opus 4.5 | легенда диаграммы |
| Gemini 3 Pro | Gemini 3 Pro | легенда диаграммы |
| GPT-5.2 (xhigh) | GPT-5.2 (xhigh) | легенда диаграммы |
| Humanity's Last Exam | Последний экзамен человечества | название бенчмарка, левый верхний график |
| SWE-bench Verified | SWE-bench Verified | название бенчмарка, второй верхний график |
| SWE-bench Multilingual | SWE-bench Multilingual | название бенчмарка, третий верхний график |
| Terminal-Bench 2.0 | Terminal-Bench 2.0 | название бенчмарка, правый верхний график |
| BrowseComp | BrowseComp | название бенчмарка, левый нижний график |
| MCP-Atlas | MCP-Atlas | название бенчмарка, второй нижний график |
| τ²-Bench | τ²-Bench | название бенчмарка, третий нижний график |
| Vending Bench 2 | Vending Bench 2 | название бенчмарка, правый нижний график |
| 50.4 | 50,4 | значение GLM-5 на Humanity's Last Exam |
| 40.8 | 40,8 | значение DeepSeek-V3.2 на Humanity's Last Exam |
| 45.4 | 45,4 | значение Claude Opus 4.5 на Humanity's Last Exam |
| 40.8 | 40,8 | значение Gemini 3 Pro на Humanity's Last Exam |
| 45.5 | 45,5 | значение GPT-5.2 на Humanity's Last Exam |
| 77.8 | 77,8 | значение GLM-5 на SWE-bench Verified |
| 80.9 | 80,9 | значение DeepSeek-V3.2 на SWE-bench Verified |
| 76.2 | 76,2 | значение Claude Opus 4.5 на SWE-bench Verified |
| 80.0 | 80,0 | значение Gemini 3 Pro на SWE-bench Verified |
| 73.3 | 73,3 | значение GLM-5 на SWE-bench Multilingual |
| 70.2 | 70,2 | значение DeepSeek-V3.2 на SWE-bench Multilingual |
| 77.5 | 77,5 | значение Claude Opus 4.5 на SWE-bench Multilingual |
| 65.0 | 65,0 | значение Gemini 3 Pro на SWE-bench Multilingual |
| 72.0 | 72,0 | значение GPT-5.2 на SWE-bench Multilingual |
| 56.2 | 56,2 | значение GLM-5 на Terminal-Bench 2.0 |
| 46.4 | 46,4 | значение DeepSeek-V3.2 на Terminal-Bench 2.0 |
| 59.3 | 59,3 | значение Claude Opus 4.5 на Terminal-Bench 2.0 |
| 54.2 | 54,2 | значение Gemini 3 Pro на Terminal-Bench 2.0 |
| 54.0 | 54,0 | значение GPT-5.2 на Terminal-Bench 2.0 |
| 75.9 | 75,9 | значение GLM-5 на BrowseComp |
| 53.4 | 53,4 | значение DeepSeek-V3.2 на BrowseComp |
| 67.8 | 67,8 | значение Claude Opus 4.5 на BrowseComp |
| 59.2 | 59,2 | значение Gemini 3 Pro на BrowseComp |
| 65.8 | 65,8 | значение GPT-5.2 на BrowseComp |
| 67.8 | 67,8 | значение GLM-5 на MCP-Atlas |
| 62.2 | 62,2 | значение DeepSeek-V3.2 на MCP-Atlas |
| 65.2 | 65,2 | значение Claude Opus 4.5 на MCP-Atlas |
| 66.6 | 66,6 | значение Gemini 3 Pro на MCP-Atlas |
| 68.0 | 68,0 | значение GPT-5.2 на MCP-Atlas |
| 89.7 | 89,7 | значение GLM-5 на τ²-Bench |
| 85.3 | 85,3 | значение DeepSeek-V3.2 на τ²-Bench |
| 91.6 | 91,6 | значение Claude Opus 4.5 на τ²-Bench |
| 90.7 | 90,7 | значение Gemini 3 Pro на τ²-Bench |
| 86.5 | 86,5 | значение GPT-5.2 на τ²-Bench |
| $4,432 | 4 432 $ | значение GLM-5 на Vending Bench 2 |
| $1,034 | 1 034 $ | значение DeepSeek-V3.2 на Vending Bench 2 |
| $4,907 | 4 907 $ | значение Claude Opus 4.5 на Vending Bench 2 |
| $5,478 | 5 478 $ | значение Gemini 3 Pro на Vending Bench 2 |
| $3,591 | 3 591 $ | значение GPT-5.2 на Vending Bench 2 |
| Figure 1: | Рисунок 1: | начало подписи к рисунку |
| Results of GLM-5, DeepSeek-V3.2, Claude Opus 4.5, Gemini 3 Pro, and GPT-5.2 (xhigh) on 8 agentic, reasoning, and coding benchmarks: | Результаты GLM-5, DeepSeek-V3.2, Claude Opus 4.5, Gemini 3 Pro и GPT-5.2 (xhigh) на 8 бенчмарках агентной работы, логического мышления и программирования: | подпись к рисунку |

## Перевод для alt-текста
Сравнительная диаграмма результатов модели GLM-5 с конкурирующими моделями на восьми бенчмарках агентной работы, логического мышления и программирования, демонстрирующая лидирующие позиции GLM-5.